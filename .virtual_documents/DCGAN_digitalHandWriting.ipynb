import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.utils as utils
import matplotlib.pyplot as plt
from tqdm import tqdm


DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
DATA_PATH = './data'
BATCH_SIZE = 64
IMAGE_CHANNEL = 1
Z_DIM = 128
G_HIDDEN = 64
D_HIDDEN = 64
X_DIM = 64
EPOCH_NUM = 20
REAL_LABEL = 1
FAKE_LABEL = 0
lr = 1e-4
seed = 7
cudnn.benchmark = True


dataset = datasets.MNIST(
    root=DATA_PATH, 
    download=True,
    transform=transforms.Compose([
        transforms.Resize(X_DIM),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
)


dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
dataloader


real_batch = next(iter(dataloader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Training Images")
plt.imshow(np.transpose(utils.make_grid(real_batch[0].to('cpu')[:64], padding=2, normalize=True).cpu(), (1,2,0)))


size = real_batch[0].size()
size


real_batch[1]


noise = torch.randn(size[0], Z_DIM, 1, 1, device=DEVICE)
noise.shape


def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.layers = nn.Sequential(
            # 1st hidden layer
            nn.ConvTranspose2d(Z_DIM, G_HIDDEN*8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(G_HIDDEN*8),
            nn.ReLU(True),
            # 2nd hidden layer
            nn.ConvTranspose2d(G_HIDDEN*8, G_HIDDEN*4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(G_HIDDEN*4),
            nn.ReLU(True),
            # 3rd hidden layer
            nn.ConvTranspose2d(G_HIDDEN*4, G_HIDDEN*2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(G_HIDDEN*2),
            nn.ReLU(True),
            # 4th hidden layer
            nn.ConvTranspose2d(G_HIDDEN*2, G_HIDDEN, 4, 2, 1, bias=False),
            nn.BatchNorm2d(G_HIDDEN),
            nn.ReLU(True),
            # output layer
            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),
            nn.Tanh()
        )
    def forward(self, input):
        # return size (BATCH_SIZE, 64, 64, 1)
        return self.layers(input)


class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.layers = nn.Sequential(
            # 1st layer BATCH_SIZEx64x64x1
            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN),
            nn.LeakyReLU(0.2, inplace=True),
            # BATCH_SIZEx32x32xD_HIDDEN
            # 2nd layer
            nn.Conv2d(D_HIDDEN, D_HIDDEN*2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN*2),
            nn.LeakyReLU(0.2, inplace=True),
            # BATCH_SIZEx16x16xD_HIDDEN*2
            # 3rd layer
            nn.Conv2d(D_HIDDEN*2, D_HIDDEN*4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN*4),
            nn.LeakyReLU(0.2, inplace=True),
            # BATCH_SIZEx8x8xD_HIDDEN*4
            # 4th layer
            nn.Conv2d(D_HIDDEN*4, D_HIDDEN*8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN*8),
            nn.LeakyReLU(0.2, inplace=True),
            # BATCH_SIZEx4x4xD_HIDDEN*8
            # output layer 
            nn.Conv2d(D_HIDDEN*8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
            # BATCH_SIZEx1x1x1
        )
    def forward(self, input):
        # return size (BATCH_SIZE,)
        return self.layers(input).view(-1, 1).squeeze(1)


# Create the generator
netG = Generator().to(DEVICE)
netG.apply(weights_init)
print(netG)


# Create the discriminator
netD = Discriminator().to(DEVICE)
netD.apply(weights_init)
print(netD)


criterion = nn.BCELoss()
# set optimizers for both G and D
optimizerD = optim.Adam(netD.parameters(), lr=lr)
optimizerG = optim.Adam(netG.parameters(), lr=lr)


# Lists to keep track of progress
img_list = []
G_losses = []
D_losses = []
iters = 0
viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=DEVICE)

print("Starting Training Loop...")
for epoch in range(EPOCH_NUM):
    for i, data in enumerate(dataloader, 0):

        # (1) Update the discriminator with real data
        netD.zero_grad()
        # Format batch
        real_cpu = data[0].to(DEVICE)
        b_size = real_cpu.size(0)
        label = torch.full((BATCH_SIZE,), REAL_LABEL, dtype=torch.float, device=DEVICE)
        # Forward pass real batch through D
        output = netD(real_cpu).view(-1)
        # Calculate loss on all-real batch
        errD_real = criterion(output, label)
        # Calculate gradients for D in backward pass
        errD_real.backward()
        D_x = output.mean().item()

        # (2) Update the discriminator with fake data
        # Generate batch of latent vectors
        noise = torch.randn(b_size, Z_DIM, 1, 1, device=DEVICE)
        # Generate fake image batch with G
        fake = netG(noise)
        label.fill_(FAKE_LABEL)
        # Classify all fake batch with D
        output = netD(fake.detach()).view(-1)
        # Calculate D's loss on the all-fake batch
        errD_fake = criterion(output, label)
        # Calculate the gradients for this batch, accumulated (summed) with previous gradients
        errD_fake.backward()
        D_G_z1 = output.mean().item()
        # Compute error of D as sum over the fake and the real batches
        errD = errD_real + errD_fake
        # Update D
        optimizerD.step()

        # (3) Update the generator with fake data
        netG.zero_grad()
        label.fill_(REAL_LABEL)  # fake labels are real for generator cost
        # Since we just updated D, perform another forward pass of all-fake batch through D
        output = netD(fake).view(-1)
        # Calculate G's loss based on this output
        errG = criterion(output, label)
        # Calculate gradients for G
        errG.backward()
        D_G_z2 = output.mean().item()
        # Update G
        optimizerG.step()

        # Output training stats
        if i % 50 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                  % (epoch, EPOCH_NUM, i, len(dataloader),
                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

        # Save Losses for plotting later
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        # Check how the generator is doing by saving G's output on fixed_noise
        if (iters % 500 == 0) or ((epoch == EPOCH_NUM-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake = netG(viz_noise).detach().cpu()
            img_list.append(utils.make_grid(fake, padding=2, normalize=True))

        iters += 1


# Grab a batch of real images from the dataloader
real_batch = next(iter(dataloader))

# Plot the real images
plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(utils.make_grid(real_batch[0].to(DEVICE)[:64], padding=5, normalize=True).cpu(),(1,2,0)))

# Plot the fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.show()


torch.save(netD.state_dict(), './models/DCGAN/netD.pth')
torch.save(netG.state_dict(), './models/DCGAN/netG.pth')


from PIL import Image

frame_list = [((img - img.min()) / (img.max() - img.min()) * 255) for img in img_list]
frames = [
    Image.fromarray(
        np.transpose(frame.cpu().numpy(), (1, 2, 0)).astype('uint8')  # 将 Tensor 转换为 NumPy 数组
    )
    for frame in frame_list
]

# 保存为 GIF
frames[0].save('./models/DCGAN/output.gif', save_all=True, append_images=frames[1:], duration=500, loop=0)




