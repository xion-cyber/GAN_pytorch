{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613e5965-4b60-44b5-b3ce-6473db4208e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faee6c2d-d175-4cd9-a7df-a0687f18f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "START_TRAIN_IMG_SIZE = 16\n",
    "DATASET = \"./data/anime-faces\"\n",
    "\n",
    "CHECKPOINT_GEN = \"./models/PGGAN_generator.pth\"\n",
    "CHECKPOINT_DIS = \"./models/PGGAN_discriminator.pth\"\n",
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = False\n",
    "\n",
    "LR = 1e-4\n",
    "BATCH_SIZES = [32, 32, 32, 32, 16, 16, 16, 4, 4, 4]\n",
    "IMAGE_SIZE = 128\n",
    "IMG_CHANNELS = 3\n",
    "Z_DIM = 256\n",
    "IN_CHANNELS = 256\n",
    "LAMBDA_GP = 10\n",
    "NUM_STEPS = int(log2(IMAGE_SIZE/4)) + 1\n",
    "\n",
    "PROGRESSIVE_EPOCHS = [4] * len(BATCH_SIZES)\n",
    "FIXED_NOISE = torch.randn(8, Z_DIM, 1, 1).to(DEVICE)\n",
    "NUM_WORKERs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d310ae-441e-49d6-bf31-3279b093487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets(\n",
    "    root='./data/anime-faces', \n",
    "    transforom=transforms([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ccffc6-8ba3-4237-8528-9e2ab61fa856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2(START_TRAIN_IMG_SIZE/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bafe21-2315-4425-b124-c70a3a8d2acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyFirst",
   "language": "python",
   "name": "myfirst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
